<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <id>2</id>
  <title>Combined summary - Adjusted difficulty depending on relative blocksize</title>
  <updated>2023-05-19T21:32:18.339705+00:00</updated>
  <author>
    <name>Anthony Towns 2015-08-14 14:20:35</name>
  </author>
  <author>
    <name>Anthony Towns 2015-08-14 15:00:25</name>
  </author>
  <link href="bitcoin-dev/Aug_2015/010213_Adjusted-difficulty-depending-on-relative-blocksize.xml" rel="alternate"/>
  <link href="bitcoin-dev/Aug_2015/010216_Adjusted-difficulty-depending-on-relative-blocksize.xml" rel="alternate"/>
  <generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator>
  <entry>
    <id>2</id>
    <title>Combined summary - Adjusted difficulty depending on relative blocksize</title>
    <updated>2023-05-19T21:32:18.339705+00:00</updated>
    <link href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2015-August/010213.html" rel="alternate"/>
    <summary>In a mailing list discussion dating back to August 14, 2015, Jakob Rönnbäck proposed adjusting the difficulty of individual blocks depending on their size relative to the average block size of the previous difficulty period. Anthony Towns replied that this would increase confirmation times as block sizes grew. He suggested that dynamically adjusting the maximum block size would be simpler and better. Rönnbäck asked if it would matter in the long run since the same amount of miners would be investing the same amount of money in mining blocks. However, Towns warned that once block sizes had normalised as much larger than 1MB with a corresponding higher average hash rate, a bad actor could easily mine a raft of valid empty/small blocks at the minimum hash rate and force a reorg (and do double spends, etc).</summary>
    <published>2015-08-14T14:20:35+00:00</published>
  </entry>
</feed>
